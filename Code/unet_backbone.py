# -*- coding: utf-8 -*-
"""Unet_backbone.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bL2Jt-w4TAx7bUlnN4SQ-SlTlDalMVQe
"""

pip install git+https://github.com/qubvel/segmentation_models #Pre-trained segmentation models module is installed

# reference: https://github.com/bnsreenu/python_for_microscopists/blob/master/210_multiclass_Unet_using_VGG_resnet_inception.py

import tensorflow as tf
#import segmentation_models as sm
import glob
import cv2
import os
import numpy as np
from matplotlib import pyplot as plt
import keras

from tensorflow.keras.utils import normalize
from keras.metrics import MeanIoU

#Resizing images, if needed
SIZE_X = 224
SIZE_Y = 224
n_classes=1 #Number of classes for segmentation

#Capture training image info as a list
train_images = []

import os
from tqdm import tqdm
from skimage.io import imread, imshow
from skimage.transform import resize
import matplotlib.pyplot as plt
from PIL import Image
from PIL import ImageOps
import random
from classification_models.keras import Classifiers
from PIL import Image
import scipy.misc
import imageio
import os
from skimage import io
import numpy as np
from matplotlib import pyplot as plt
import pandas as pd

#My personal Drive is mounted here which has all the dataset and models

from google.colab import drive
drive.mount('/content/drive')
directory='/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/train'

TRAIN_PATH1 = '/content/drive/MyDrive/oral cancer Images/Newimages/'
TRAIN_PATH2 = '/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/train/non-cancer'
TEST_PATH1 = '/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/val/cancer'
TEST_PATH2 = '/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/val/non-cancer'

train_ids1 = next(os.walk(TEST_PATH2))[2]
train_ids2 = next(os.walk(TRAIN_PATH2))[2]
test_ids1 = next(os.walk(TEST_PATH1))[2]
test_ids2 = next(os.walk(TEST_PATH2))[2]
LENTRAIN = len(train_ids1)+len(train_ids2)
LENTEST = len(test_ids1)+len(test_ids2)
image_directory = '/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/train/resized cancer'
mask_directory = '/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/train/resized masks'

#Further, images are loaded in an numpy array, resized and stored back in the model. Similarly, hand-curated masks or ground truth is loaded from the drive

image_names = glob.glob("/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/train/resized cancer/*")
#image_names = glob.glob("/content/drive/MyDrive/oral cancer Images/nir/*")
image_names.sort()
image_names_subset = image_names[0:233]
images = [cv2.imread(img) for img in image_names_subset]
train_images = np.array(images)
#train_images = np.expand_dims(image_dataset, axis = 3)

image_names = glob.glob("/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/train/resized cancer/*")
image_names.sort()
image_names_subset = image_names[0:109]
images = [cv2.imread(img) for img in image_names_subset]
experiment = np.array(images)
#train_images = np.expand_dims(image_dataset, axis = 3)

mask_names = glob.glob("/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/train/resized masks/*")
mask_names.sort()
mask_names_subset = mask_names[0:233]
masks = [cv2.imread(mask, 0) for mask in mask_names_subset]
masks = [np.where(mask>0, 1, mask) for mask in masks]
mask_dataset = np.array(masks)
train_masks = np.expand_dims(mask_dataset, axis = 3)

import numpy as np
import cv2

#img = cv2.imread("images/BSE_Image.jpg")
img = train_images[0]

#img = cv2.imread("images/BSE.tif", 0)

#Denoise for better results
#from skimage.restoration import denoise_tv_chambolle
#denoised_img = denoise_tv_chambolle(img, weight=0.1, eps=0.0002, n_iter_max=200, multichannel=False)
plt.imshow(img, cmap='gray')
plt.hist(img.flat, bins=100, range=(100,255))

#We convert the unit8 values to float as it is a requirement of the k-means method of OpenCV
img2 = np.float32(train_images[0])

#Define criteria, number of clusters and apply k-means
#When this criterion is satisfied, the algorithm iteration stops.
#cv.TERM_CRITERIA_EPS — stop the algorithm iteration if specified accuracy, epsilon, is reached.
#cv.TERM_CRITERIA_MAX_ITER — stop the algorithm after the specified number of iterations, max_iter.
#cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER — stop the iteration when any of the above condition is met.
#Max iterations, in this example 10.
#Epsilon, required accuracy, in this example 1.0

criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)

# Number of clusters
k = 30

# Number of attempts, number of times algorithm is executed using different initial labelings.
#Algorithm return labels that yield best compactness.
#compactness : It is the sum of squared distance from each point to their corresponding centers.

attempts = 10

#other flags needed as inputs for K-means
#Specify how initial seeds are taken.
#Two options, cv.KMEANS_PP_CENTERS and cv.KMEANS_RANDOM_CENTERS

ret,label,center=cv2.kmeans(img2, k, None, criteria, attempts, cv2.KMEANS_PP_CENTERS)

#cv2.kmeans outputs 2 parameters.
#1 COmpactness.
#2 Labels: Label array.
#3 Center. the array of centers of clusters. For k=4 we will have 4 centers.
#For RGB image, we will have center for each image, so tota 4x3 = 12.
#Now convert center values from float32 back into uint8.
center = np.uint8(center)

#Next, we have to access the labels to regenerate the clustered image
res = center[label.flatten()]
res2 = res.reshape((img.shape)) #Reshape labels to the size of original image
cv2.imwrite("segmented.jpg", res2)

for i in range(len(train_images)):
  img = train_images[i]
  img2 = np.float32(train_images[i])

  ret,label,center=cv2.kmeans(img2, k, None, criteria, attempts, cv2.KMEANS_PP_CENTERS)
  center = np.uint8(center)

  #Next, we have to access the labels to regenerate the clustered image
  res = center[label.flatten()]
  res2 = res.reshape((img.shape)) #Reshape labels to the size of original image
  train_images[i] = res2









img = cv2.imread("/content/nwb.jpg")
img = cv2.resize(img, (SIZE_Y, SIZE_X))
imageio.imwrite("/content/nwb.jpg", img)



np.unique(train_masks)

train_images = []
i=0
for directory_path in glob.glob("/content/drive/MyDrive/oral cancer Images/Newimages/"):
    for img_path in glob.glob(os.path.join(directory_path, "*")):
        img = cv2.imread(img_path, 1)
        img = cv2.resize(img, (SIZE_Y, SIZE_X))

        train_images.append(img)
        scipy.misc.imsave("/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/train/cancer/" + i, img)
        i=i+1

train_images = np.array(train_images)

train_images.shape

#Capture mask/label info as a list
train_masks = []
for directory_path in glob.glob("/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/train/resized masks/"):
    for mask_path in glob.glob(os.path.join(directory_path, "*")):
        mask = cv2.imread(mask_path, 0)
        my_mask = np.where(mask>0, 1, mask)
        #my_mask =  np.expand_dims(resize(my_mask, (SIZE_Y, SIZE_X), mode='constant', preserve_range=True), axis=-1)
        #my_mask = cv2.resize(my_mask, (SIZE_Y, SIZE_X), interpolation = cv2.INTER_NEAREST)  #Otherwise ground truth changes due to interpolation
        train_masks.append(my_mask)

#Convert list to array for machine learning processing
train_masks = np.array(train_masks)
train_masks = np.expand_dims(train_masks, axis = 3)

print("Image data shape is: ", train_images.shape)
print("Mask data shape is: ", train_masks.shape)
print("Max pixel value in image is: ", train_images.max())
print("Labels in the mask are : ", np.unique(train_masks))

#Sanity check, view few images
import random

image_number = random.randint(0, 82)
#plt.figure(figsize=(12, 6))
plt.subplot(121)
plt.imshow(train_images[image_number,:,:,0], cmap='gray')
plt.subplot(122)
plt.imshow(train_masks[image_number,:,:,0], cmap='gray')
plt.show()
image_number

print(np.unique(train_masks[0]))
#train_images = np.zeros((LENTRAIN, SIZE_Y, SIZE_X, 3), dtype=np.uint8)
#train_masks = np.zeros((LENTRAIN, SIZE_Y, SIZE_X, 1), dtype=np.uint8)

train_images = np.zeros((124, SIZE_Y, SIZE_X, 3), dtype=np.uint8)
train_masks = np.zeros((124, SIZE_Y, SIZE_X, 1), dtype=np.uint8)
print('Resizing training images')
for n, id_ in tqdm(enumerate(train_ids1), total=len(train_ids1)):
    path = TEST_PATH2
    img = imread(path + '/' + id_)[:,:,:3]
    img = resize(img, (SIZE_Y, SIZE_X), mode='constant', preserve_range=True)
    imageio.imwrite("/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/val/resized nc/" +id_, img)
    #scipy.misc.imsave("/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/train/resized cancer/" + id_, img)
    #train_images[n] = img  #Fill empty X_train with values from img
#train_images = np.array(train_images)



train_masks.shape

#Add additional daatset from different source

mask = np.zeros((SIZE_Y, SIZE_X, 1), dtype=np.uint8)
i=0
for mask_file in next(os.walk('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/train/resized masks'))[2]:
  z = imread('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/train/resized masks/'+ mask_file)

  z =  np.expand_dims(resize(z, (SIZE_Y, SIZE_X), mode='constant', preserve_range=True), axis=-1)
  #z = resize(z, (SIZE_Y, SIZE_X), mode='constant', preserve_range=True)
  mask = np.maximum(mask,z)
  my_mask = np.where(z>0, 1, z)
  train_masks[i] = my_mask
  i = i+1
train_masks = np.array(train_masks)
#train_masks = np.expand_dims(train_masks, axis = 3)

# img = Image.open('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/train/mask/'+ mask_file)

 # gray=img.resize((224,224),Image.ANTIALIAS)
 # gray.save('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/train/resized masks/'+ mask_file )

# NOT NEEDED in binary classification
from sklearn.preprocessing import LabelEncoder
labelencoder = LabelEncoder()
n, h, w, c = train_masks.shape
train_masks_reshaped = train_masks.reshape(-1,1)
train_masks_reshaped_encoded = labelencoder.fit_transform(train_masks_reshaped)
train_masks_encoded_original_shape = train_masks_reshaped_encoded.reshape(n, h, w, c)

np.unique(train_masks_encoded_original_shape)

train_masks.shape #total number of training data : 170 Images

train_masks_input = np.expand_dims(train_masks_encoded_original_shape, axis=3)

train_images.shape

train_masks_input.shape

#Create a subset of data for quick testing
#Picking 10% for testing and remaining for training
from sklearn.model_selection import train_test_split
X1, X_test, y1, y_test = train_test_split(train_images, train_masks, test_size = 0.25, random_state = 0)

#Sanity check, view few mages
import random

image_number = random.randint(0, len(X1)-1)
#plt.figure(figsize=(12, 6))
plt.subplot(121)
plt.imshow(X1[image_number,:,:,0], cmap='gray')
plt.subplot(122)
plt.imshow(y1[image_number,:,:,0], cmap='gray')
plt.show()

# NOT NEEDED for now

#Further split training data t a smaller subset for quick testing of models
X_train, X_do_not_use, y_train, y_do_not_use = train_test_split(X1, y1, test_size = 0.5, random_state = 0)

print("Class values in the dataset are ... ", np.unique(y_train))

# NOT NEEDED in binary classification

from tensorflow.keras.utils import to_categorical
#train_masks_cat = to_categorical(y_train, num_classes=n_classes)
#y_train_cat = train_masks_cat.reshape((y_train.shape[0], y_train.shape[1], y_train.shape[2], n_classes))
y_train_cat = y_train.reshape((y_train.shape[0], y_train.shape[1], y_train.shape[2], n_classes))

test_masks_cat = to_categorical(y_test, num_classes=2)
y_test_cat = test_masks_cat.reshape((y_test.shape[0], y_test.shape[1], y_test.shape[2], 2))
tf.cast(y_test_cat, tf.float64)

# U-net model initialization:

#Reused parameters in all models

n_classes=1
activation='sigmoid'

LR = 0.0001

optim = tf.keras.optimizers.Adam(LR)

# Segmentation models losses can be combined together by '+' and scaled by integer or float factor
# set class weights for dice_loss (car: 1.; pedestrian: 2.; background: 0.5;)
dice_loss = sm.losses.DiceLoss(class_weights=np.array([0.25, 0.25, 0.25, 0.25]))
focal_loss = sm.losses.CategoricalFocalLoss()
total_loss = dice_loss + (1 * focal_loss)

# actulally total_loss can be imported directly from library, above example just show you how to manipulate with losses
# total_loss = sm.losses.binary_focal_dice_loss # or sm.losses.categorical_focal_dice_loss

metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]

import segmentation_models as sm
sm.set_framework('tf.keras')
sm.framework()

#Below here, many models are loaded and trained on this set of data. Each model and their predictions are saved in the drive for future use so we don't have to train them again for every session.

###Model 1
BACKBONE1 = 'resnet34'
preprocess_input1 = sm.get_preprocessing(BACKBONE1)
#ResNet18, preprocess_input = Classifiers.get('resnet18')
#resnet = ResNet18((224, 224, 3), include_top=False)
#preprocess_input1 = resnet

# preprocess input
X_train1 = preprocess_input1(X1)
X_test1 = preprocess_input1(X_test)

# define model
model1 = sm.Unet(BACKBONE1, encoder_weights='imagenet', classes=n_classes, activation=activation)

# compile keras model with defined optimozer, loss and metrics
model1.compile(optim, loss='binary_crossentropy', metrics=metrics)

#model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=metrics)

print(model1.summary())

# Training the model
history1=model1.fit(X1,
          y1,
          batch_size=16,
          epochs=50,
          verbose=1,
          validation_data=(X_test, y_test))

# convert the history.history dict to a pandas DataFrame:
hist_df = pd.DataFrame(history1.history)

# or save to csv: Predicted csv file is saved to drive for analysis later
hist_csv_file = '/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/ModelsR6/history1.csv'
with open(hist_csv_file, mode='w') as f:
    hist_df.to_csv(f)

his1 = pd.read_csv('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/ModelsR6/history1.csv')

model1.save('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/ModelsR6/res34_25p_val_50epochs.hdf5')
#Model is saved to the drive as well

#Graph to show iou_score of the model on the data
fig1 = plt.gcf()
plt.plot(his1['iou_score'])
plt.plot(his1['val_iou_score'])
plt.axis(ymin=0,ymax=1)
plt.grid()
plt.title('uNet with ResNet Backbone Model')
plt.ylabel('Accuracy')
plt.xlabel('Epochs')
plt.legend(['iou-score', 'val_iou_score'])
plt.show()

###Model 2

BACKBONE2 = 'inceptionv3'
preprocess_input2 = sm.get_preprocessing(BACKBONE2)

# preprocess input
X_train2 = preprocess_input2(X1)
X_test2 = preprocess_input2(X_test)

# define model
model2 = sm.Unet(BACKBONE2, encoder_weights='imagenet', classes=n_classes, activation=activation)


# compile keras model with defined optimozer, loss and metrics
model2.compile(optim, loss='binary_crossentropy', metrics=metrics)
#model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=metrics)


#print(model2.summary())

# Training the model

history2=model2.fit(X1,
          y1,
          batch_size=16,
          epochs=50,
          verbose=1,
          validation_data=(X_test, y_test))

# convert the history.history dict to a pandas DataFrame:
hist_df = pd.DataFrame(history2.history)

# or save to csv:
hist_csv_file = '/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/ModelsR6/history2.csv'
with open(hist_csv_file, mode='w') as f:
    hist_df.to_csv(f)

his2 = pd.read_csv('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/ModelsR6/history2.csv')

model2.save('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/ModelsR6/inceptionv3_25p_val_50epochs.hdf5')

fig1 = plt.gcf()
plt.plot(history2.history['iou_score'])
plt.plot(history2.history['val_iou_score'])
plt.axis(ymin=0,ymax=1)
plt.grid()
plt.title('uNet with inceptionV3 Backbone')
plt.ylabel('Accuracy')
plt.xlabel('Epochs')
plt.legend(['iou-score', 'val_iou_score'])
plt.show()

###Model 3

BACKBONE3 = 'resnext101'
preprocess_input3 = sm.get_preprocessing(BACKBONE3)

# preprocess input
X_train3 = preprocess_input3(X1)
X_test3 = preprocess_input3(X_test)


# define model
model3 = sm.Unet(BACKBONE3, encoder_weights='imagenet', classes=n_classes, activation=activation)

# compile keras model with defined optimozer, loss and metrics
model3.compile(optim, loss='binary_crossentropy', metrics=metrics)
#model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=metrics)


print(model3.summary())

history3=model3.fit(X1,
          y1,
          batch_size=8,
          epochs=50,
          verbose=1,
          validation_data=(X_test, y_test))

with open('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/History/trainHistoryDict', 'wb') as file_pi_1:
   pickle.dump(history1.history, file_pi_1)

model3.save('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/Models/resnext101_backbone_50epochs.hdf5')

fig1 = plt.gcf()
plt.plot(history3.history['iou_score'])
plt.plot(history3.history['f1-score'])
plt.axis(ymin=0,ymax=1)
plt.grid()
plt.title('uNet with vgg16 Backbone Model')
plt.ylabel('Accuracy')
plt.xlabel('Epochs')
plt.legend(['iou-score', 'f1-score'])
plt.show()

#plot the training and validation accuracy and loss at each epoch
loss = history1.history['loss']
val_loss = history1.history['val_loss']
epochs = range(1, len(loss) + 1)
plt.plot(epochs, loss, 'y', label='Training loss')
plt.plot(epochs, val_loss, 'r', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

acc = history1.history['iou_score']
loss = history1.history['loss']
val_acc = history1.history['val_iou_score']
epochs = range(1, len(loss) + 1)
plt.plot(epochs, acc, 'y', label='Training IOU')
plt.plot(epochs, val_acc, 'r', label='Validation IOU')
plt.title('Training and validation IOU')
plt.xlabel('Epochs')
plt.ylabel('IOU')
plt.legend()
plt.show()

acc = history2.history['iou_score']
loss = history2.history['loss']
val_acc = history2.history['val_iou_score']
epochs = range(1, len(loss) + 1)
plt.plot(epochs, acc, 'y', label='Training IOU')
plt.plot(epochs, val_acc, 'r', label='Validation IOU')
plt.title('Training and validation IOU')
plt.xlabel('Epochs')
plt.ylabel('IOU')
plt.legend()
plt.show()

acc = history3.history['iou_score']
loss = history3.history['loss']
val_acc = history3.history['val_iou_score']
epochs = range(1, len(loss) + 1)
plt.plot(epochs, acc, 'y', label='Training IOU')
plt.plot(epochs, val_acc, 'r', label='Validation IOU')
plt.title('Training and validation IOU')
plt.xlabel('Epochs')
plt.ylabel('IOU')
plt.legend()
plt.show()

###Model 4

BACKBONE4 = 'resnet101'
preprocess_input4 = sm.get_preprocessing(BACKBONE4)

# preprocess input
X_train4 = preprocess_input4(X1)
X_test4 = preprocess_input4(X_test)


# define model
model4 = sm.Unet(BACKBONE4, encoder_weights='imagenet', classes=n_classes, activation=activation)

# compile keras model with defined optimozer, loss and metrics
model4.compile(optim, loss='binary_crossentropy', metrics=metrics)
#model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=metrics)


#print(model4.summary())

history4=model4.fit(X1,
          y1,
          batch_size=16,
          epochs=50,
          verbose=1,
          validation_data=(X_test, y_test))

# convert the history.history dict to a pandas DataFrame:
hist_df = pd.DataFrame(history4.history)

# or save to csv:
hist_csv_file = '/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/ModelsR6/history4.csv'
with open(hist_csv_file, mode='w') as f:
    hist_df.to_csv(f)

his4 = pd.read_csv('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/ModelsR6/history4.csv')

his4 = pd.read_csv('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/ModelsR6/history4.csv')

model4.save('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/ModelsRadd/resnet101_25_p_50epochs.hdf5')

acc = history4.history['iou_score']
loss = history4.history['loss']
val_acc = history4.history['val_iou_score']
epochs = range(1, len(loss) + 1)
plt.plot(epochs, acc, 'y', label='Training IOU')
plt.plot(epochs, val_acc, 'r', label='Validation IOU')
plt.title('Training and validation IOU')
plt.xlabel('Epochs')
plt.ylabel('IOU')
plt.legend()
plt.show()

###Model 7

#BACKBONE7 = 'NULL'
#preprocess_input7 = sm.get_preprocessing(BACKBONE7)

# preprocess input
#X_train7 = preprocess_input7(X1)
#X_test7 = preprocess_input7(X_test)


# define model
model7 = sm.Unet(encoder_weights='imagenet', classes=n_classes, activation=activation)

# compile keras model with defined optimozer, loss and metrics
model7.compile(optim, loss='binary_crossentropy', metrics=metrics)
#model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=metrics)


print(model7.summary())

history7=model7.fit(X1,
          y1,
          batch_size=8,
          epochs=50,
          verbose=1,
          validation_data=(X_test, y_test))

# convert the history.history dict to a pandas DataFrame:
hist_df = pd.DataFrame(history7.history)

# or save to csv:
hist_csv_file = '/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/ModelsR6/history7.csv'
with open(hist_csv_file, mode='w') as f:
    hist_df.to_csv(f)

his7 = pd.read_csv('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/ModelsR6/history7.csv')

his7 = pd.read_csv('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/ModelsR6/history7.csv')

model7.save('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/ModelsRadd/noBackbone_25_p_50epochs.hdf5')

acc = history7.history['iou_score']
loss = history7.history['loss']
val_acc = history7.history['val_iou_score']
epochs = range(1, len(loss) + 1)
plt.plot(epochs, acc, 'y', label='Training IOU')
plt.plot(epochs, val_acc, 'r', label='Validation IOU')
plt.title('Training and validation IOU')
plt.xlabel('Epochs')
plt.ylabel('IOU')
plt.legend()
plt.show()

###Model 5

BACKBONE5 = 'efficientnetb7'
preprocess_input5 = sm.get_preprocessing(BACKBONE5)

# preprocess input
X_train5 = preprocess_input5(X1)
X_test5 = preprocess_input5(X_test)


# define model
model5 = sm.Unet(BACKBONE5, encoder_weights='imagenet', classes=n_classes, activation=activation)

# compile keras model with defined optimozer, loss and metrics
model5.compile(optim, loss='binary_crossentropy', metrics=metrics)
#model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=metrics)


print(model5.summary())

history5=model5.fit(X1,
          y1,
          batch_size=8,
          epochs=50,
          verbose=1,
          validation_data=(X_test, y_test))

acc = history5.history['iou_score']
loss = history5.history['loss']
val_acc = history5.history['val_iou_score']
epochs = range(1, len(loss) + 1)
plt.plot(epochs, acc, 'y', label='Training IOU')
plt.plot(epochs, val_acc, 'r', label='Validation IOU')
plt.title('Training and validation IOU')
plt.xlabel('Epochs')
plt.ylabel('IOU')
plt.legend()
plt.show()

model5.save('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/Models/efficientnetb7_backbone_50epochs.hdf5')

###Model 6

BACKBONE6 = 'densenet201'
preprocess_input6 = sm.get_preprocessing(BACKBONE6)

# preprocess input
X_train6 = preprocess_input6(X1)
X_test6 = preprocess_input6(X_test)


# define model
model6 = sm.Unet(BACKBONE6, encoder_weights='imagenet', classes=n_classes, activation=activation)

# compile keras model with defined optimozer, loss and metrics
model6.compile(optim, loss='binary_crossentropy', metrics=metrics)
#model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=metrics)


print(model6.summary())

history6=model6.fit(X1,
          y1,
          batch_size=8,
          epochs=50,
          verbose=1,
          validation_data=(X_test, y_test))

acc = history6.history['iou_score']
loss = history6.history['loss']
val_acc = history6.history['val_iou_score']
epochs = range(1, len(loss) + 1)
plt.plot(epochs, acc, 'y', label='Training IOU')
plt.plot(epochs, val_acc, 'r', label='Validation IOU')
plt.title('Training and validation IOU')
plt.xlabel('Epochs')
plt.ylabel('IOU')
plt.legend()
plt.show()

model6.save('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/Models/densenet201_backbone_50epochs.hdf5')

acc1 = his1['iou_score']
acc2 = his2['iou_score']
acc4 = his4['iou_score']
epochs = range(1, len(acc1) + 1)
plt.plot(epochs, acc1, 'y', label='ResNet34')
plt.plot(epochs, acc2, 'r', label='InceptionV3')
plt.plot(epochs, acc4, 'b', label='ResNet101')
plt.title('Training IOU Comparison')
plt.xlabel('Epochs')
plt.ylabel('IOU')
plt.legend()
plt.show()
# IOU Score of three models are compared here

acc1 = his1['loss']
acc2 = his2['loss']
acc4 = his4['loss']
epochs = range(1, len(acc1) + 1)
plt.plot(epochs, acc1, 'y', label='ResNet34')
plt.plot(epochs, acc2, 'r', label='InceptionV3')
plt.plot(epochs, acc4, 'b', label='ResNet101')
plt.title('Training Loss Comparison')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()
# Loss of three models are compared here

acc1 = his1['f1-score']
acc2 = his2['f1-score']
acc4 = his4['f1-score']
epochs = range(1, len(acc1) + 1)
plt.plot(epochs, acc1, 'y', label='ResNet34')
plt.plot(epochs, acc2, 'r', label='InceptionV3')
plt.plot(epochs, acc4, 'b', label='ResNet101')
plt.title('Dice Coefficient Comparison')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()
# Dice Coefficient of three models are compared here









from keras.models import load_model

### FOR NOW LET US FOCUS ON A SINGLE MODEL

#Models are loaded back from the drive for further use
#NOTE: These models took hours and at times multiple tries to train the whole dataset. So it was essential to save them in our drive abd then use them as here for next sessions:

#Set compile=False as we are not loading it for training, only for prediction.
model1 = load_model('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/ModelsR6/res34_25p_val_50epochs.hdf5', compile=False)
model2 = load_model('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/ModelsR6/inceptionv3_25p_val_50epochs.hdf5', compile=False)
#model3 = load_model('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/Models/resnext101_backbone_50epochs.hdf5', compile=False)
model4 = load_model('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/ModelsRadd/resnet101_25_p_50epochs.hdf5', compile=False)
#model5 = load_model('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/Models/efficientnetb7_backbone_50epochs.hdf5', compile=False)
#model6 = load_model('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/Models/densenet201_backbone_50epochs.hdf5', compile=False)

#IOU
y_pred1 = model1.predict(X1)
#y_pred1_argmax=np.argmax(y_pred1, axis=3)

#NP array of training images is passed to the models which give us output of predictions in np array fromat

#Using built in keras function
#from keras.metrics import MeanIoU
n_classes = 2
IOU_keras = MeanIoU(num_classes=n_classes)
IOU_keras.update_state(y1, y_pred1)

overlap = y1[:,:,:,:] * y_pred1[:,:,:,:] # Logical AND
overlap = np.where(overlap[:,:,:,:] > 0.5, 1, 0)

union = y1[:,:,:,:] + y_pred1[:,:,:,:] # Logical OR
union = np.where(union[:,:,:,:] > 0.5, 1, 0)

IOU = overlap.sum()/float(union.sum())

print(np.unique(y1[:,:,:,0]))
print(np.unique(y_pred1[:,:,:,0]))
#print(np.unique(y_pred1_argmax[:,:,0]))
print(np.unique(overlap[:,:,:,0]))
print(np.unique(union[:,:,:,0]))

#overlap[:,:,:,1] = [1 if a_ > 0.5 else 0 for a_ in overlap[:,:,:] ]
#overlap = np.where(overlap[:,:,:,:] > 0.5, 1, 0)
#overlaps = [np.where(overlap[:,:,:,0]>0.5, 1, overlap[:,:,:,0]) for overlap[:,:,:,:] in overlap]
#print(np.unique(overlap[:,:,:,:]))

#print("Mean IoU =", IOU_keras.result().numpy())
IOU

#To calculate I0U for each class...
values = np.array(IOU_keras.get_weights()).reshape(n_classes, n_classes)
print(values)
class1_IoU = values[0,0]/(values[0,0] + values[0,1] + values[1,0])
class2_IoU = values[1,1]/(values[1,1] + values[1,0] + values[0,1])

print("IoU for class1 is: ", class1_IoU)
print("IoU for class2 is: ", class2_IoU)

#Verify the prediction on first image
plt.imshow(train_images[0])

plt.title('Image Label')
plt.imshow(train_masks[0][:,:,0])

test_img_input1 = preprocess_input3(train_images[1])
test_pred1 = model4.predict(test_img_input1)
test_prediction1 = np.argmax(test_pred1, axis=3)[0,:,:]
#im = Image.fromarray(test_prediction1)
#im.save(d+f"{i}.jpeg")

#y_img = np.argmax(ground_truth, axis=3)
plt.title('Prediction Image')
plt.imshow(test_prediction1[0])

#from keras.preprocessing.image import img_to_array
from tensorflow.keras.utils import load_img, img_to_array
img1 = load_img('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/train/resized cancer/3.jpg', target_size=(224, 224)) #VGG user 224 as input
#imgM1 = load_img('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/train/resized masks/3.jpg', target_size=(224, 224)) #VGG user 224 as input
#img3 = load_img('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/train/resized cancer/3.jpg', target_size=(224, 224)) #VGG user 224 as input

# convert the image to an array
img = img_to_array(img1)
#imgM1 = img_to_array(img2)
#img3 = img_to_array(img3)
# expand dimensions to match the shape of model input
img1 = np.expand_dims(img1, axis=0)

#NOT WORKING. CHECK NEXT BLOCK

import random
from PIL import Image
test_img_number = 0
#for i in range(len(train_images)):

#test_img = train_images[test_img_number]
#test_img = img1
#ground_truth = train_masks[test_img_number]
#test_img_input = np.expand_dims(test_img, 0)

#test_img_input1 = preprocess_input1(test_img_input)

#test_pred1 = model1.predict(test_img_input1)
#test_prediction1 = np.argmax(test_pred1, axis=3)
#im = Image.fromarray(test_prediction1)
#im.save(d+f"{i}.jpeg")
prediction = (model2.predict(img1)[0,:,:,0] > 0.5).astype(np.uint8)

#y_img = np.argmax(ground_truth, axis=3)
plt.subplot(231)
plt.title('Testing Image')
#plt.imshow(train_images[test_img_number])
plt.imshow(img)
#plt.savefig("Testing image.png")
#im.save(d+f"{i}.jpeg")

#plt.subplot(232)
#plt.title('Testing Label')
#gt=ground_truth[:,:,0]
#plt.imshow(gt)
#plt.savefig("Testing labe.png")

plt.subplot(232)
plt.title('Prediction')
plt.imshow(prediction)
plt.legend(['malign', 'benign'])
#plt.savefig("Prediction image.png")

features = model4.predict(test_img_input)
train_features = features.reshape(features.shape[0], features.shape[-1], features.shape[1], features.shape[2])
filename = 'Resnet101_features'
np.savez(filename, feature = train_features)

btlneck = np.load('Resnet101_features.npz')
train_features = btlneck['feature']

#Not using this block

import random
from PIL import Image
test_img_number = random.randint(0, len(train_images))
for i in range(len(train_images)):
  test_img = train_images[i]
  ground_truth=train_masks[i]
  test_img_input=np.expand_dims(test_img, 0)

  #test_img_input1 = preprocess_input3(test_img_input)

  prediction = (model4.predict(test_img_input)[0,:,:,0] > 0.5).astype(np.uint8)
  #prediction = model2.predict(test_img_input1)
  #test_prediction1 = np.argmax(prediction, axis=3)
  #im = Image.fromarray(test_prediction1)
  # im.save(d+f"{i}.jpeg")

  #y_img = np.argmax(ground_truth, axis=3)
  plt.subplot(231)
  plt.title('X Train: Input')
  plt.imshow(train_images[i])
  #plt.savefig("Testing image.png")
  #im.save(d+f"{i}.jpeg")

  plt.subplot(232)
  plt.title('Y_train: Mask')
  gt=ground_truth[:,:,0]
  plt.imshow(gt)
  #plt.savefig("Testing labe.png")

  plt.subplot(233)
  plt.title('Prediction')
  plt.imshow(prediction)
  #plt.legend(['malign', 'benign'])
  plt.savefig("/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/ModelsR3/Predictions/Resnet101_p/" + str(i) +  ".png")

#Predictions from all the models are loaded here

#preds = [model.predict(X_test) for model in models]

pred_threshold = 0.5

pred1 = model1.predict(train_images)

pred2 = model2.predict(train_images)

#pred3 = model3.predict(train_images)

pred4 = model4.predict(train_images)

#pred5 = model5.predict(train_images)

#pred6 = model6.predict(train_images)

pred1_b = np.where(pred1[:,:,:,:] > pred_threshold, 1, 0)

pred2_b = np.where(pred2[:,:,:,:] > pred_threshold, 1, 0)

#pred3_b = np.where(pred3[:,:,:,:] > pred_threshold, 1, 0)

pred4_b = np.where(pred4[:,:,:,:] > pred_threshold, 1, 0)

#pred5_b = np.where(pred5[:,:,:,:] > pred_threshold, 1, 0)

#pred6_b = np.where(pred6[:,:,:,:] > pred_threshold, 1, 0)

#Predictions are noramlized, with values above a certain threshold being 1 and others 0

#IOU Score is calculated here from the predictions

overlap_threshold = 0.5
union_threshold = 0.99

overlap1 = train_masks[:,:,:,:] * pred1[:,:,:,:] # Logical AND
overlap1 = np.where(overlap1[:,:,:,:] > overlap_threshold, 1, 0)
overlap2 = train_masks[:,:,:,:] * pred2[:,:,:,:] # Logical AND
overlap2 = np.where(overlap2[:,:,:,:] > overlap_threshold, 1, 0)
#overlap3 = train_masks[:,:,:,:] * pred3[:,:,:,:] # Logical AND
#overlap3 = np.where(overlap3[:,:,:,:] > overlap_threshold, 1, 0)
overlap4 = train_masks[:,:,:,:] * pred4[:,:,:,:] # Logical AND
overlap4 = np.where(overlap4[:,:,:,:] > overlap_threshold, 1, 0)
#overlap5 = train_masks[:,:,:,:] * pred5[:,:,:,:] # Logical AND
#overlap5 = np.where(overlap5[:,:,:,:] > overlap_threshold, 1, 0)
#overlap6 = train_masks[:,:,:,:] * pred6[:,:,:,:] # Logical AND
#overlap6 = np.where(overlap6[:,:,:,:] > overlap_threshold, 1, 0)

union1 = train_masks[:,:,:,:] + pred1[:,:,:,:] # Logical OR
union1 = np.where(union1[:,:,:,:] > union_threshold, 1, 0)
union2 = train_masks[:,:,:,:] + pred2[:,:,:,:] # Logical OR
union2 = np.where(union2[:,:,:,:] > union_threshold, 1, 0)
#union3 = train_masks[:,:,:,:] + pred3[:,:,:,:] # Logical OR
#union3 = np.where(union3[:,:,:,:] > union_threshold, 1, 0)
union4 = train_masks[:,:,:,:] + pred4[:,:,:,:] # Logical OR
union4 = np.where(union4[:,:,:,:] > union_threshold, 1, 0)
#union5 = train_masks[:,:,:,:] + pred5[:,:,:,:] # Logical OR
#union5 = np.where(union5[:,:,:,:] > union_threshold, 1, 0)
#union6 = train_masks[:,:,:,:] + pred6[:,:,:,:] # Logical OR
#union6 = np.where(union6[:,:,:,:] > union_threshold, 1, 0)

IOU1 = overlap1.sum()/float(union1.sum())
IOU2 = overlap2.sum()/float(union2.sum())
#IOU3 = overlap3.sum()/float(union3.sum())
IOU4 = overlap4.sum()/float(union4.sum())
#IOU5 = overlap5.sum()/float(union5.sum())
#IOU6 = overlap6.sum()/float(union6.sum())

print('IOU Score for model1 = ', IOU1)
print('IOU Score for model2 = ', IOU2)
#print('IOU Score for model3 = ', IOU3)
print('IOU Score for model4 = ', IOU4)
#print('IOU Score for model5 = ', IOU5)
#print('IOU Score for model6 = ', IOU6)

#Weighted average approach to calculate IOU Score

from sklearn.metrics import accuracy_score
#Weighted average ensemble
weights = [0.3, 0.5, 0.3]
preds=np.array([pred1, pred2, pred4])

#Use tensordot to sum the products of all elements over specified axes.
weighted_preds = np.tensordot(preds, weights, axes=((0),(0)))
weighted_ensemble_prediction = np.argmax(weighted_preds, axis=3)

union_threshold = 0.99
overlap_threshold = 0.99

#print(np.unique(weighted_preds[:,:,:,0]))

overlap = train_masks[:,:,:,:] * weighted_preds[:,:,:,:] # Logical AND
overlap = np.where(overlap[:,:,:,:] > overlap_threshold, 1, 0)

union = train_masks[:,:,:,:] + weighted_preds[:,:,:,:] # Logical OR
union = np.where(union[:,:,:,:] > union_threshold, 1, 0)

IOU = overlap.sum()/float(union.sum())
IOU

#Grid search for the best combination of w1, w2, w3 that gives maximum acuracy

import pandas as pd
df = pd.DataFrame([])

models = [ model1, model2, model4]
preds=np.array([ pred1, pred2, pred4])

union_threshold = 0.99
overlap_threshold = 0.5

for w1 in range(0, 10):
    for w2 in range(0, 10):
        for w3 in range(0, 10):
            wts = [w1/10.,w2/10.,w3/10.]

            wted_preds = np.tensordot(preds, wts, axes=((0),(0)))

            #wted_ensemble_pred = np.argmax(wted_preds, axis=3)
            if(w1+w2+w3 > 9):
              overlap = train_masks[:,:,:,:] * wted_preds[:,:,:,:] # Logical AND
              overlap = np.where(overlap[:,:,:,:] > overlap_threshold, 1, 0)

              union = train_masks[:,:,:,:] + wted_preds[:,:,:,:] # Logical OR
              union = np.where(union[:,:,:,:] > union_threshold, 1, 0)

              IOU = overlap.sum()/float(union.sum())
              print("Now predciting for weights :", w1/10., w2/10., w3/10., " : IOU = ", IOU)
              df = df.append(pd.DataFrame({'wt1':wts[0],'wt2':wts[1],
                                         'wt3':wts[2], 'IOU': IOU}, index=[0]), ignore_index=True)

max_iou_row = df.iloc[df['IOU'].idxmax()]
print("Max IOU of ", max_iou_row[3], " obained with w1=", max_iou_row[0],
      " w2=", max_iou_row[1], " and w3=", max_iou_row[2])


#############################################################

#Grid search for 4 models
#Grid search for the best combination of w1, w2, w3 that gives maximum acuracy

import pandas as pd
df = pd.DataFrame([])

models = [ model1, model2, model4, model6]
preds=np.array([ pred1, pred2, pred4, pred6])

union_threshold = 0.99
overlap_threshold = 0.5

for w1 in range(0, 10):
    for w2 in range(0, 10):
        for w3 in range(0, 10):
          for w4 in range(0, 10):
            wts = [w1/10.,w2/10.,w3/10.,w4/10.]

            wted_preds = np.tensordot(preds, wts, axes=((0),(0)))

            #wted_ensemble_pred = np.argmax(wted_preds, axis=3)
            if(w1+w2+w3+w4 == 14):
              overlap = train_masks[:,:,:,:] * wted_preds[:,:,:,:] # Logical AND
              overlap = np.where(overlap[:,:,:,:] > overlap_threshold, 1, 0)

              union = train_masks[:,:,:,:] + wted_preds[:,:,:,:] # Logical OR
              union = np.where(union[:,:,:,:] > union_threshold, 1, 0)

              IOU = overlap.sum()/float(union.sum())
              print("Now predciting for weights :", w1/10., w2/10., w3/10., w4/10., " : IOU = ", IOU)
              df = df.append(pd.DataFrame({'wt1':wts[0],'wt2':wts[1],
                                         'wt3':wts[2], 'wt4':wts[3], 'IOU': IOU}, index=[0]), ignore_index=True)

max_iou_row = df.iloc[df['IOU'].idxmax()]
print("Max IOU of ", max_iou_row[4], " obained with w1=", max_iou_row[0],
      " w2=", max_iou_row[1], " and w3=", max_iou_row[2],  " and w4=", max_iou_row[3])


#############################################################

from sklearn.metrics import accuracy_score
#Weighted average ensemble
weights = [0.4, 0.5, 0.5]
preds=np.array([pred1, pred2, pred4])

#Use tensordot to sum the products of all elements over specified axes.
weighted_preds = np.tensordot(preds, weights, axes=((0),(0)))
weighted_ensemble_prediction = np.argmax(weighted_preds, axis=3)

union_threshold = 1.5
overlap_threshold = 0.5

#print(np.unique(weighted_preds[:,:,:,0]))

overlap = train_masks[:,:,:,:] * weighted_preds[:,:,:,:] # Logical AND
overlap = np.where(overlap[:,:,:,:] > overlap_threshold, 1, 0)

union = train_masks[:,:,:,:] + weighted_preds[:,:,:,:] # Logical OR
union = np.where(union[:,:,:,:] > union_threshold, 1, 0)

IOU = overlap.sum()/float(union.sum())
IOU

wts = [0.6,0.9,0.4]
preds=np.array([ pred1, pred2, pred4])
wted_preds = np.tensordot(preds, wts, axes=((0),(0)))

for i in range(len(wted_preds)):
  weighted_preds = np.where(wted_preds[:,:,:,:] > 0.5, 1, 0)
n = 1

# The best possible weights are then added to the prediction and then ran on example cancer images below

from scipy.cluster.hierarchy import centroid, fcluster
from scipy.spatial.distance import pdist
import cv2

#Input shape to the model is 224 x 224. SO resize input image to this shape.
from tensorflow.keras.utils import load_img, img_to_array
img1 = load_img('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/train/nc.jpg', target_size=(224, 224)) #VGG user 224 as input

img = cv2.imread("/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/train/nc.jpg")
img = cv2.resize(img, (SIZE_Y, SIZE_X))

# convert the image to an array
img1 = img_to_array(img)
img11 = np.expand_dims(img1, axis=0)

preddd = model1.predict(img11)
for i in range(len(preddd)):
  weighted_preds = np.where(preddd[:,:,:,:] > 0.5, 1, 0)
n = 1

n=n+1
plt.subplot(231)
prediction = pred4_b[n]
prediction = prediction[:,:,0]
plt.title('Mask')
plt.imshow(train_images[n])
ground_truth=train_masks[n]
gt=ground_truth[:,:,0]
plt.imshow(gt, cmap='jet', alpha=0.5)
#plt.text(10, 10, 'Cancer', bbox=dict(fill=False, edgecolor='red', linewidth=2))
#plt.savefig("Testing image.png")
#im.save(d+f"{i}.jpeg")

#plt.subplot(232)
#plt.title('Testing Label')
#plt.legend(['Yellow = Legion', 'Purple = Non-Legion'])
#ground_truth=train_masks[n]
#gt=ground_truth[:,:,0]
#plt.imshow(gt)
#plt.savefig("Testing labe.png")

plt.subplot(232)
prediction = pred4_b[n]
prediction = prediction[:,:,0]
plt.title('Prediction')
plt.imshow(train_images[n])
plt.imshow(prediction, cmap='jet', alpha=0.5)
cancer_pixels = np.array(np.where(prediction == 1))
text_border = cancer_pixels[:,0]

plt.text((text_border[0]-30),(text_border[1]-30), 'Cancer', color="white", bbox=dict(fill=False, edgecolor='red', linewidth=0))
#plt.savefig("Testing image.png")
#im.save(d+f"{i}.jpeg")


#plt.subplot(234)
#plt.title('Prediction')
#prediction = weighted_preds[n]
#prediction = prediction[:,:,0]
#plt.imshow(prediction)

img = cv2.imread("/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/train/nc7.jpg")
img = cv2.resize(img, (SIZE_Y, SIZE_X))
imageio.imwrite("/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/train/nnc7.jpg", img)

#Input shape to the model is 224 x 224. SO resize input image to this shape.
from tensorflow.keras.utils import load_img, img_to_array
img1 = load_img('/content/nwb.jpg', target_size=(224, 224)) #VGG user 224 as input

img = cv2.imread("/content/nwb.jpg")
img = cv2.resize(img, (SIZE_Y, SIZE_X))

# convert the image to an array
img11 = img_to_array(img)
img11 = np.expand_dims(img1, axis=0)

preddd = model1.predict(img11)
for i in range(len(preddd)):
  weighted_preds = np.where(preddd[:,:,:,:] > 0.1, 1, 0)

plt.subplot(231)
#prediction = img11
#prediction = prediction[:,:,0]
plt.title('Actual')
plt.imshow(img1)
#plt.imshow(gt, cmap='jet', alpha=0.5)

plt.subplot(232)
prediction = weighted_preds[0]
prediction = prediction[:,:,0]
plt.title('Prediction')
plt.imshow(img11[0])
plt.imshow(prediction, cmap='jet', alpha=0.5)
cancer_pixels = np.array(np.where(prediction == 1))
text_border = cancer_pixels[:,0]

plt.text((text_border[0]),(text_border[1]), 'Non-cancer', color="white", bbox=dict(fill=False, edgecolor='red', linewidth=0))
#plt.savefig("Testing image.png")
#im.save(d+f"{i}.jpeg")


#plt.subplot(234)
#plt.title('Prediction')
#prediction = weighted_preds[n]
#prediction = prediction[:,:,0]
#plt.imshow(prediction)

import random
from PIL import Image
test_img_number = random.randint(0, len(train_images))
for i in range(len(train_images)):
  test_img = train_images[i]
  ground_truth=train_masks[i]
  test_img_input=np.expand_dims(test_img, 0)

  #test_img_input1 = preprocess_input3(test_img_input)

  #prediction = (model4.predict(test_img_input)[0,:,:,0] > 0.5).astype(np.uint8)
  prediction = weighted_preds[i]
  prediction = prediction[:,:,0]
  #prediction = model2.predict(test_img_input1)
  #test_prediction1 = np.argmax(prediction, axis=3)
  #im = Image.fromarray(test_prediction1)
  # im.save(d+f"{i}.jpeg")

  #y_img = np.argmax(ground_truth, axis=3)
  plt.subplot(231)
  plt.title('X Train: Input')
  plt.imshow(train_images[i])
  #plt.savefig("Testing image.png")
  #im.save(d+f"{i}.jpeg")

  plt.subplot(232)
  plt.title('Y_train: Mask')
  gt=ground_truth[:,:,0]
  plt.imshow(gt)
  #plt.savefig("Testing labe.png")

  plt.subplot(233)
  plt.title('Prediction')
  plt.imshow(prediction)
  plt.savefig("/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/Hybrid predictions/" + str(i) +  ".png")



import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import glob
import cv2
import pickle

from keras.models import Sequential, Model
from keras.layers import Conv2D
import os
from keras.applications.vgg16 import VGG16
from keras.applications.resnet import ResNet101
from tensorflow.keras.applications.inception_v3 import InceptionV3
from keras.applications.resnet import ResNet50
from keras.models import Sequential
from keras.layers.core import Flatten, Dense, Dropout
from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D
from tensorflow.keras.optimizers import SGD
import numpy as np
from matplotlib import pyplot as plt
from keras.models import Model

#Understand the filters in the model
#Let us pick the first hidden layer as the layer of interest.
layer1 = model1.layers #Conv layers at 1, 3, 6, 8, 11, 13, 15
filters = model1.layers[3].get_weights()
print(layer1[3].name)

layer2 = model2.layers #Conv layers at 1, 3, 6, 8, 11, 13, 15
filters = model2.layers[3].get_weights()
print(layer2[1].name)

layer4 = model4.layers #Conv layers at 1, 3, 6, 8, 11, 13, 15
filters = model4.layers[3].get_weights()
print(layer4[3].name)



# plot filters

fig1=plt.figure(figsize=(8, 12))
columns = 8
rows = 8
n_filters = columns * rows
for i in range(1, n_filters +1):
    f = filters[0][: ,: ,: ,[i-1]]
    fig1 =plt.subplot(rows, columns, i)
    fig1.set_xticks([])  #Turn off axis
    fig1.set_yticks([])
    plt.imshow(f[:, :,:, 0], cmap='gray') #Show only the filters from 0th channel (R)
    #ix += 1
plt.show()

conv_layer_index1 =[]
conv_layer_index2 =[]
conv_layer_index4 =[]

for i in range(199):
  if layer1[i].name.find('conv') != -1:
    conv_layer_index1.append(i)

for i in range(352):
  if layer2[i].name.find('conv') != -1:
    conv_layer_index2.append(i)

for i in range(418):
  if layer4[i].name.find('conv') != -1:
    conv_layer_index4.append(i)

#### Now plot filter outputs

#Define a new truncated model to only include the conv layers of interest
#conv_layer_index = [1, 3, 6, 8, 11, 13, 15]
#conv_layer_index = [1, 3, 6]  #TO define a shorter model
outputs1 = [model1.layers[i].output for i in conv_layer_index1]
model_short1 = Model(inputs=model1.inputs, outputs=outputs1)

outputs2 = [model2.layers[i].output for i in conv_layer_index2]
model_short2 = Model(inputs=model2.inputs, outputs=outputs2)

outputs4 = [model4.layers[i].output for i in conv_layer_index4]
model_short4 = Model(inputs=model4.inputs, outputs=outputs4)

print(model_short1.summary())

#Input shape to the model is 224 x 224. SO resize input image to this shape.
from tensorflow.keras.utils import load_img, img_to_array
img10 = load_img('/content/nwb.jpg', target_size=(224, 224)) #VGG user 224 as input
#img2 = load_img('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/train/resized cancer/100.jpg', target_size=(224, 224)) #VGG user 224 as input
#img3 = load_img('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/train/resized cancer/107.jpeg', target_size=(224, 224)) #VGG user 224 as input

# convert the image to an array
img1 = img_to_array(img10)
#img2 = img_to_array(img2)
#img3 = img_to_array(img3)

# expand dimensions to match the shape of model input
img11 = np.expand_dims(img1, axis=0)
#img22 = np.expand_dims(img2, axis=0)
#img33 = np.expand_dims(img3, axis=0)

img3 = np.expand_dims(train_images[2], axis=0)

# Generate feature output by predicting on the input image
feature_output1 = model_short1.predict(img11)

columns = 8
rows = 8
for ftr in feature_output1:
    #pos = 1
    fig=plt.figure(figsize=(12, 12))
    for i in range(1, columns*rows +1):
        fig =plt.subplot(rows, columns, i)
        fig.set_xticks([])  #Turn off axis
        fig.set_yticks([])
        plt.imshow(ftr[0, :, :, i-1], cmap='gray')
        #pos += 1
    plt.show()

feature_output2 = model_short4.predict(img1)

columns = 5
rows = 5
for ftr in feature_output2:
    #pos = 1
    fig=plt.figure(figsize=(12, 12))
    for i in range(1, columns*rows +1):
        fig =plt.subplot(rows, columns, i)
        fig.set_xticks([])  #Turn off axis
        fig.set_yticks([])
        plt.imshow(ftr[0, :, :, i-1], cmap='gray')
        #pos += 1
    plt.show()

feature_output4 = model_short4.predict(img1)

columns = 8
rows = 8
for ftr in feature_output4:
    #pos = 1
    fig=plt.figure(figsize=(12, 12))
    for i in range(1, columns*rows +1):
        fig =plt.subplot(rows, columns, i)
        fig.set_xticks([])  #Turn off axis
        fig.set_yticks([])
        plt.imshow(ftr[0, :, :, i-1], cmap='gray')
        #pos += 1
    plt.show()

tpr

fpr

# CONFUSION MATRIX for binary image segmentationmodels
import seaborn as sns

FP = len(np.where(weighted_preds - train_masks  == 1)[0])
FN = len(np.where(weighted_preds - train_masks  == -1)[0])
TP = len(np.where(weighted_preds + train_masks ==2)[0])
TN = len(np.where(weighted_preds + train_masks == 0)[0])
cmat = [[TP, FN], [FP, TN]]
fpr = FP/(FP+TN)
tpr = TP/(TP+FN)

plt.figure(figsize = (6,6))
sns.heatmap(cmat/np.sum(cmat), cmap="Reds", annot=True, fmt = '.2%', square=1,   linewidth=2.)
plt.xlabel("predictions")
plt.ylabel("real values")
plt.title("Conf Matrix for Weighted preds")
plt.show()

from sklearn.metrics import roc_curve, auc # roc curve tools
from skimage.filters import gaussian

#pred1 = model1.predict(X_test)

ground_truth_labels = y_test.ravel() # we want to make them into vectors
score_value = pred1.ravel() # we want to make them into vectors

fpr, tpr, _ = roc_curve(ground_truth_labels,score_value)
roc_auc = auc(fpr,tpr)

fig, ax = plt.subplots(1,1)
ax.plot(fpr, tpr, label='Raw ROC curve (area = %0.2f)' % roc_auc)
ax.plot([0, 1], [0, 1], 'k--')
ax.set_xlim([0.0, 1.0])
ax.set_ylim([0.0, 1.05])
ax.set_xlabel('False Positive Rate')
ax.set_ylabel('True Positive Rate')
ax.set_title('ROC Curve (Resnet34 backbone)')
ax.legend(loc="lower right")

#pred2 = model2.predict(X_test)

ground_truth_labels = y_test.ravel() # we want to make them into vectors
score_value = pred2.ravel() # we want to make them into vectors

fpr, tpr, _ = roc_curve(ground_truth_labels,score_value)
roc_auc = auc(fpr,tpr)

fig, ax = plt.subplots(1,1)
ax.plot(fpr, tpr, label='Raw ROC curve (area = %0.2f)' % roc_auc)
ax.plot([0, 1], [0, 1], 'k--')
ax.set_xlim([0.0, 1.0])
ax.set_ylim([0.0, 1.05])
ax.set_xlabel('False Positive Rate')
ax.set_ylabel('True Positive Rate')
ax.set_title('ROC Curve (InceptionV3 backbone)')
ax.legend(loc="lower right")

#pred4 = model4.predict(X_test)

ground_truth_labels = y_test.ravel() # we want to make them into vectors
score_value = pred4.ravel() # we want to make them into vectors

fpr, tpr, _ = roc_curve(ground_truth_labels,score_value)
roc_auc = auc(fpr,tpr)

fig, ax = plt.subplots(1,1)
ax.plot(fpr, tpr, label='Raw ROC curve (area = %0.2f)' % roc_auc)
ax.plot([0, 1], [0, 1], 'k--')
ax.set_xlim([0.0, 1.0])
ax.set_ylim([0.0, 1.05])
ax.set_xlabel('False Positive Rate')
ax.set_ylabel('True Positive Rate')
ax.set_title('ROC Curve (Resnet101 backbone)')
ax.legend(loc="lower right")

pred4 = model4.predict(X1)
pred2 = model2.predict(X1)
pred1 = model1.predict(X1)

ground_truth_labels = y1.ravel() # we want to make them into vectors
score_value4 = pred4.ravel()
score_value2 = pred2.ravel()
score_value1 = pred1.ravel()

fpr1, tpr1, _ = roc_curve(ground_truth_labels,score_value1)
roc_auc1 = auc(fpr1,tpr1)
fpr2, tpr2, _ = roc_curve(ground_truth_labels,score_value2)
roc_auc2 = auc(fpr2,tpr2)
fpr4, tpr4, _ = roc_curve(ground_truth_labels,score_value4)
roc_auc4 = auc(fpr4,tpr4)

fig, ax = plt.subplots(1,1)
ax.plot(fpr1, tpr1, label='ResNet34 (area = %0.2f)' % roc_auc1)
ax.plot(fpr2, tpr2, label='InceptionV3 (area = %0.2f)' % roc_auc2)
ax.plot(fpr4, tpr4, label='ResNet101 (area = %0.2f)' % roc_auc4)
ax.plot([0, 1], [0, 1], 'k--')
ax.set_xlim([0.0, 1.0])
ax.set_ylim([0.0, 1.05])
ax.set_xlabel('False Positive Rate')
ax.set_ylabel('True Positive Rate')
ax.set_title('ROC Curve Comparision)')
ax.legend(loc="lower right")



from sklearn import metrics

y_true = []
y_pred = []
for pred in pred1_b:
  #pred = model1.predict(img)  # get prediction for each pixel in the image
  # flatten all targets
  y_pred.append(pred.flatten())  # flatten all predictions

for true_seg in train_masks:
  y_true.append(true_seg.flatten())

# concatenate all predictions and targets:
y_true = np.concatenate(y_true, axis=0)
y_pred = np.concatenate(y_pred, axis=0)
# copte the ROC curve
fpr, tpr, thresholds = metrics.roc_curve(y_true, y_pred)
plt.figure(1)
plt.plot([0, 1], [0, 1], 'y--')
plt.plot(fpr, tpr, marker='.')
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.show()

y_true = []
y_pred = []
for pred in pred2_b:
  #pred = model1.predict(img)  # get prediction for each pixel in the image
  # flatten all targets
  y_pred.append(pred.flatten())  # flatten all predictions

for true_seg in train_masks:
  y_true.append(true_seg.flatten())

# concatenate all predictions and targets:
y_true = np.concatenate(y_true, axis=0)
y_pred = np.concatenate(y_pred, axis=0)
# copte the ROC curve
fpr, tpr, thresholds = metrics.roc_curve(y_true, y_pred)
plt.figure(1)
plt.plot([0, 1], [0, 1], 'y--')
plt.plot(fpr, tpr, marker='.')
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.show()

y_true = []
y_pred = []
for pred in pred4:
  #pred = model1.predict(img)  # get prediction for each pixel in the image
  # flatten all targets
  y_pred.append(pred.flatten())  # flatten all predictions

for true_seg in train_masks:
  y_true.append(true_seg.flatten())

# concatenate all predictions and targets:
y_true = np.concatenate(y_true, axis=0)
y_pred = np.concatenate(y_pred, axis=0)
# copte the ROC curve
fpr, tpr, thresholds = metrics.roc_curve(y_true, y_pred)
plt.figure(1)
plt.plot([0, 1], [0, 1], 'y--')
plt.plot(fpr, tpr, marker='.')
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.show()



import matplotlib.pyplot as plt
import matplotlib.image as mpimg

plt.style.use('classic')
#############################################################
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, BatchNormalization
from keras.layers import Activation, Dropout, Flatten, Dense
#from keras import backend as K
####################################################
import os
import cv2
from PIL import Image
import numpy as np

dataset = []  #Many ways to handle data, you can use pandas. Here, we are using a list format.
label = []  #Place holders to define add labels. We will add 0 to all parasitized images and 1 to uninfected.

image_names = glob.glob("/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/train/resized cancer/*")
#image_names = glob.glob("/content/drive/MyDrive/oral cancer Images/nir/*")
image_names.sort()
image_names_subset = image_names[0:233]
#images = [cv2.imread(img) for img in image_names_subset]
for img in image_names_subset:
  dataset.append(cv2.imread(img))
  label.append(1)
#label = label.append(0) for img in image_names_subset]
#train_images = np.array(images)
#train_images = np.expand_dims(image_dataset, axis = 3)

image_names2 = glob.glob("/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/val/resized nc/*")
#image_names = glob.glob("/content/drive/MyDrive/oral cancer Images/nir/*")
image_names2.sort()
image_names_subset2 = image_names2[0:52]
#images = [cv2.imread(img) for img in image_names_subset]

#label = label.append(0) for img in image_names_subset]
#train_images = np.expand_dims(image_dataset, axis = 3)
for img in image_names_subset2:
  dataset.append(cv2.imread(img))
  label.append(0)

dataset = np.array(dataset)
label = np.array(label)
np.array(label, dtype=bool)

from sklearn.model_selection import train_test_split
#from keras.utils import to_categorical

X_train, X_test, y_train, y_test = train_test_split(dataset, label, test_size = 0.20, random_state = 0)

#Without scaling (normalize) the training may not converge.
#Normalization is a rescaling of the data from the original range
#so that all values are within the range of 0 and 1.
from tensorflow.keras.utils import normalize
X_train = normalize(X_train, axis=1)
X_test = normalize(X_test, axis=1)

INPUT_SHAPE = (224, 224, 3)   #change to (SIZE, SIZE, 3)

import matplotlib.pyplot as plt
import numpy as np
import PIL
import tensorflow as tf
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
from keras.layers import Activation, Dense, Flatten

resnet_model = Sequential()

pretrained_model= tf.keras.applications.ResNet101(include_top=False,
                   input_shape=INPUT_SHAPE,
                   pooling='max',classes=1,
                   weights='imagenet')
for layer in pretrained_model.layers:
        layer.trainable=False

resnet_model.add(pretrained_model)

resnet_model.add(Flatten())
resnet_model.add(Dense(512, activation='relu'))
resnet_model.add(Dense(1, activation='sigmoid'))

resnet_model.summary()

resnet_model.compile(optimizer=Adam(lr=0.001),loss='binary_crossentropy',metrics=['accuracy'])

#history = resnet_model.fit(X_train, validation_data=y_train, epochs=10)

history=resnet_model.fit(X_train,
          y_train,
          batch_size=16,
          epochs=20,
          verbose=1,
          validation_data=(X_test, y_test))

resnet_model.save('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/C_Models/resnet101_20epochs.hdf5')

fig1 = plt.gcf()
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.axis(ymin=0.4,ymax=1)
plt.grid()
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epochs')
plt.legend(['train', 'validation'])
plt.show()

inception_model = Sequential()

pretrained_model= tf.keras.applications.InceptionV3(include_top=False,
                   input_shape=INPUT_SHAPE,
                   pooling='max',classes=1,
                   weights='imagenet')
for layer in pretrained_model.layers:
        layer.trainable=False

inception_model.add(pretrained_model)

inception_model.add(Flatten())
inception_model.add(Dense(512, activation='relu'))
inception_model.add(Dense(1, activation='sigmoid'))

inception_model.summary()

inception_model.compile(optimizer=Adam(lr=0.001),loss='binary_crossentropy',metrics=['accuracy'])

history2=inception_model.fit(X_train,
          y_train,
          batch_size=16,
          epochs=20,
          verbose=1,
          validation_data=(X_test, y_test))

inception_model.save('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/C_Models/inceptionv3_20epochs.hdf5')

fig1 = plt.gcf()
plt.plot(history2.history['accuracy'])
plt.plot(history2.history['val_accuracy'])
plt.axis(ymin=0.4,ymax=1)
plt.grid()
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epochs')
plt.legend(['train', 'validation'])
plt.show()

from keras.models import load_model
# load model
resnet_model = load_model('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/C_Models/resnet101_20epochs.hdf5')
inception_model= load_model('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/C_Models/inceptionv3_20epochs.hdf5')

layers1 = resnet_model.layers
resnet_model.summary()

conv_layer_index1 =[]

for i in range(4):
  if layers1[i].name.find('conv') != -1:
    conv_layer_index1.append(i)

from keras.preprocessing.image import load_img, img_to_array
img1 = load_img('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/train/resized cancer/1.jpg', target_size=(224, 224)) #VGG user 224 as input
img2 = load_img('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/train/resized cancer/2.jpg', target_size=(224, 224)) #VGG user 224 as input
img3 = load_img('/content/drive/MyDrive/oral cancer Images/OralCancer_Kaggle/train/resized cancer/3.jpg', target_size=(224, 224)) #VGG user 224 as input

# convert the image to an array
img1 = img_to_array(img1)
img2 = img_to_array(img2)
img3 = img_to_array(img3)

# expand dimensions to match the shape of model input
img1 = np.expand_dims(img1, axis=0)
img2 = np.expand_dims(img2, axis=0)
img3 = np.expand_dims(img3, axis=0)

print("Generate a prediction")
prediction = inception_model.predict(dataset[:])
print("prediction shape:", prediction.shape)
prediction

print("Generate a prediction")
prediction = resnet_model.predict(dataset[:])
print("prediction shape:", prediction.shape)
prediction

label[:]

label.shape

_, acc = model1.evaluate(X1, y1)
print("Accuracy = ", (acc * 100.0), "%")

_, acc = resnet_model.evaluate(X_test, y_test)
print("Accuracy = ", (acc * 100.0), "%")

_, acc = inception_model.evaluate(X_test, y_test)
print("Accuracy = ", (acc * 100.0), "%")

#Confusion matrix
#We compare labels and plot them based on correct or wrong predictions.
#Since sigmoid outputs probabilities we need to apply threshold to convert to label.

mythreshold=0.5
from sklearn.metrics import confusion_matrix

y_pred = (inception_model.predict(dataset)>= mythreshold).astype(int)
cm=confusion_matrix(label, y_pred)
print(cm)

y_pred = (resnet_model.predict(dataset)>= mythreshold).astype(int)
cm=confusion_matrix(label, y_pred)
print(cm)

#ROC
from sklearn.metrics import roc_curve, auc
y_preds = resnet_model.predict(X_test).ravel()

fpr, tpr, thresholds = roc_curve(y_test, y_preds)
roc_auc = auc(fpr,tpr)

plt.figure(1)
plt.plot([0, 1], [0, 1], 'y--')
plt.plot(fpr, tpr,label='Raw ROC curve (area = %0.2f)' % roc_auc)
plt.legend(loc="lower right")
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve (Resnet101 Classifier)')

plt.show()

y_preds = inception_model.predict(X_test).ravel()

fpr, tpr, thresholds = roc_curve(y_test, y_preds)
roc_auc = auc(fpr,tpr)

plt.figure(1)
plt.plot([0, 1], [0, 1], 'y--')
plt.plot(fpr, tpr, marker='.' ,label='Raw ROC curve (area = %0.2f)' % roc_auc)
plt.legend(loc="lower right")
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve (InceptionV3 Classifier)')
plt.show()

# CONFUSION MATRIX for binary image segmentationmodels
import seaborn as sns


mythreshold=0.5
y_pred = (resnet_model.predict(dataset)>= mythreshold).astype(int)

FP = len(np.where(y_pred - label == 1)[0])
FN = len(np.where(y_pred - label == -1)[0])
TP = len(np.where(y_pred + label == 2)[0])
TN = len(np.where(y_pred + label == 0)[0])
cmat = [[TP, FN], [FP, TN]]

plt.figure(figsize = (6,6))
sns.heatmap(cmat/np.sum(cmat), cmap="Reds", annot=True, fmt = '.2%', square=1,   linewidth=2.)
plt.xlabel("predictions")
plt.ylabel("real values")
plt.show()

# CONFUSION MATRIX for binary image segmentationmodels
import seaborn as sns


mythreshold=0.5
y_pred = (inception_model.predict(X_test)>= mythreshold).astype(int)

FP = len(np.where(y_pred - y_test == 1)[0])
FN = len(np.where(y_pred - y_test == -1)[0])
TP = len(np.where(y_pred + y_test == 2)[0])
TN = len(np.where(y_pred + y_test == 0)[0])
cmat = [[TP, FN], [FP, TN]]

plt.figure(figsize = (6,6))
sns.heatmap(cmat/np.sum(cmat), cmap="Reds", annot=True, fmt = '.2%', square=1,   linewidth=2.)
plt.xlabel("predictions")
plt.ylabel("real values")
plt.show()

# CONFUSION MATRIX for binary image segmentationmodels
import seaborn as sns


mythreshold=0.5
y_pred = (inception_model.predict(dataset)>= mythreshold).astype(int)

FP = len(np.where(y_pred - label == 1)[0])
FN = len(np.where(y_pred - label == -1)[0])
TP = len(np.where(y_pred + label == 2)[0])
TN = len(np.where(y_pred + label == 0)[0])
cmat = [[TP, FN], [FP, TN]]

plt.figure(figsize = (6,6))
sns.heatmap(cmat/np.sum(cmat), cmap="Reds", annot=True, fmt = '.2%', square=1,   linewidth=2.)
plt.xlabel("predictions")
plt.ylabel("real values")
plt.show()

for i in y_pred:
  if y_pred[i] != 1:
    print(i)

y_pred

dataset[126]

np.argwhere(y_pred == 0)

